{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../../Data/bgsedsc_0.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up ----\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import time\n",
    "import scipy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,  scale\n",
    "import category_encoders as ce\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# kernel approximators\n",
    "from sklearn.kernel_approximation import Nystroem, RBFSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Random state\n",
    "rand_state = 1111\n",
    "np.random.seed(rand_state) # impose random seed for reproducibility\n",
    "\n",
    "# Training dataset\n",
    "data=pd.read_csv('../Data/mimic_train.csv')\n",
    "data_test=pd.read_csv('../Data/mimic_test_los.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outcome variable ----\n",
    "y = data['LOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "I have moved the preprocessing to a separate file as it's quite extensive and this way it's more easily shared across prediction problems. It saves data which I read below in order to not have to run pre-processing each time. If need be, pre-processing can be run by uncommenting the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./preproc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pre-processed data:\n",
    "y = data.loc[:,'LOS']\n",
    "X = pd.read_csv(\"../Data/los/X_preproc.csv\")\n",
    "X_test = pd.read_csv(\"../Data/los/X_test_preproc.csv\")\n",
    "data = pd.concat([y,X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-sampling:\n",
    "#data = data.sample(\n",
    "#    frac=0.1, random_state=rand_state\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20885, 43)\n",
      "(5221, 43)\n",
      "(20885,)\n"
     ]
    }
   ],
   "source": [
    "# Check:\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20885, 43)\n",
      "(5221, 43)\n",
      "(20885,)\n"
     ]
    }
   ],
   "source": [
    "# Check:\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "classif = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_values = {\n",
    "    'nthread':[1], #when use hyperthread, xgboost may become slower\n",
    "    'objective':['reg:squarederror'],\n",
    "    'learning_rate': [0.01,0.02], #so called `eta` value\n",
    "    'max_depth': [3,6],\n",
    "    'min_child_weight': [20],\n",
    "    'subsample': [0.5,0.75],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'n_estimators': [100,200,300], #number of trees \n",
    "    'reg_lambda':[0.5,1,1.5],\n",
    "    'reg_alpha':[0, 0.1, 0.5]\n",
    "}\n",
    "grid_acc = GridSearchCV(\n",
    "    classif, \n",
    "    param_grid = grid_values,\n",
    "    scoring = 'neg_root_mean_squared_error', cv=5\n",
    ")\n",
    "grid_acc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us analyse the grid search in some more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report best choices:\n",
    "n_est_best = str(grid_acc.best_estimator_.n_estimators)\n",
    "lr_best = str(grid_acc.best_estimator_.learning_rate)\n",
    "max_depth_best = str(grid_acc.best_estimator_.max_depth)\n",
    "subsample_best = str(grid_acc.best_estimator_.subsample)\n",
    "reg_best = str(grid_acc.best_estimator_.reg_lambda)\n",
    "min_child = str(grid_acc.best_estimator_.min_child_weight)\n",
    "alpha = str(grid_acc.best_estimator_.reg_alpha)\n",
    "score_best = str(np.round(grid_acc.best_score_, 5))\n",
    "print('Best n_estimators parameter : '+ n_est_best)\n",
    "print('Best learning rate: '+ lr_best)\n",
    "print('Best maximumg depth: '+ max_depth_best)\n",
    "print('Best subsample size: '+ subsample_best)\n",
    "print('Best reguarization param: '+ reg_best)\n",
    "print('Best min child weight: '+ min_child)\n",
    "print('Best L1 reg: '+ alpha)\n",
    "print('Accuracy score:' + score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(grid_acc, \"reg_alpha\", negative=False, display_all_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict values based on optimized parameters\n",
    "y_hat = grid_acc.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset (to produce predictions)\n",
    "data_test=pd.read_csv('../Data/mimic_test_death.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'icustay_id': data_test.icustay_id.values, 'LOS': y_hat})\n",
    "output_name = f\"output/predictions_score:{score_best}_nEst:{n_est_best}_lr:{lr_best}_maxDepth:{max_depth_best}_subsample:{subsample_best}\" \n",
    "    \n",
    "predictions.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
