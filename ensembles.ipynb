{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../../Data/bgsedsc_0.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up ----\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import time\n",
    "import scipy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,  scale\n",
    "import category_encoders as ce\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# kernel approximators\n",
    "from sklearn.kernel_approximation import Nystroem, RBFSampler\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Random state\n",
    "rand_state = 1111\n",
    "np.random.seed(rand_state) # impose random seed for reproducibility\n",
    "\n",
    "# Some base models\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import mlens\n",
    "from mlens.visualization import corrmat\n",
    "from mlens.ensemble import SuperLearner, BlendEnsemble, Subsemble, SequentialEnsemble, TemporalEnsemble\n",
    "\n",
    "# Training dataset\n",
    "data=pd.read_csv('../Data/mimic_train.csv')\n",
    "data_test=pd.read_csv('../Data/mimic_test_los.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "I have moved the preprocessing to a separate file as it's quite extensive and this way it's more easily shared across prediction problems. It saves data which I read below in order to not have to run pre-processing each time. If need be, pre-processing can be run by uncommenting the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./preproc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pre-processed data:\n",
    "y = data.loc[:,'LOS']\n",
    "X = pd.read_csv(\"../Data/los/X_preproc.csv\")\n",
    "X_test = pd.read_csv(\"../Data/los/X_test_preproc.csv\")\n",
    "data = pd.concat([y,X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-sampling:\n",
    "#data = data.sample(\n",
    "#    frac=0.1, random_state=rand_state\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20885, 41)\n",
      "(5221, 41)\n",
      "(20885,)\n"
     ]
    }
   ],
   "source": [
    "# Check:\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20885, 41)\n",
      "(5221, 41)\n",
      "(20885,)\n"
     ]
    }
   ],
   "source": [
    "# Check:\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    #Generate a library of simple learners\n",
    "    svc = SVC(C=100, probability=True, gamma='scale', random_state=SEED)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    lr = LogisticRegression(C=100, random_state=SEED, solver='lbfgs', max_iter=1000)\n",
    "    rf = RandomForestClassifier(n_estimators=10, max_features=3, random_state=SEED)\n",
    "\n",
    "    models = {'svm': svc,\n",
    "              'knn': knn,\n",
    "              'random forest': rf,\n",
    "              'logistic': lr,\n",
    "              }\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def train_predict(model_list,xtrain=xtrain,ytrain=ytrain,xtest=xtest,ytest=ytest):\n",
    "    #Fit models in list on training set and return preds\n",
    "    P = np.zeros((ytest.shape[0], len(model_list)))\n",
    "    P = pd.DataFrame(P)\n",
    "\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(xtrain, ytrain)\n",
    "        P.iloc[:, i] = m.predict_proba(xtest)[:, 1]\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P\n",
    "\n",
    "\n",
    "def score_models(P, y):\n",
    "    # Score model in test set\n",
    "    print(\"Scoring models.\")\n",
    "    scores=[]\n",
    "    for m in P.columns:\n",
    "        score = roc_auc_score(y, P.loc[:, m])\n",
    "        scores.append(score)\n",
    "        print(\"%-26s: %.3f\" % (m, score))\n",
    "    return P.columns,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "P = train_predict(models,xtrain,ytrain,xtest,ytest)\n",
    "my_models,my_scores= score_models(P, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot correlations\n",
    "sns.heatmap(P.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results=[(model,score) for model,score in zip(my_models,my_scores)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple average\n",
    "AvgPred=pd.DataFrame(P.mean(axis=1),columns=['Avg'])\n",
    "my_model_avg,my_scores_avg= score_models(AvgPred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results=results+[(model,score) for model,score in zip(my_model_avg,my_scores_avg)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = ExtraTreesClassifier(\n",
    "    n_estimators=50,\n",
    "    bootstrap=True,\n",
    "    max_features=0.7,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Instantiate the ensemble with 5 folds (stacking meta-learner)\n",
    "sl = SuperLearner(\n",
    "    folds=5,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    backend=\"multiprocessing\",\n",
    "    n_jobs=3\n",
    ")\n",
    "\n",
    "# Add the base learners and the meta learner\n",
    "sl.add(list(models.values()), proba=True)\n",
    "sl.add_meta(meta_learner, proba=True)\n",
    "\n",
    "# Train the ensemble\n",
    "sl.fit(xtrain, ytrain)\n",
    "\n",
    "# Predict the test set\n",
    "p_sl = sl.predict_proba(xtest2)\n",
    "scoreStackXtres=roc_auc_score(ytest2, p_sl[:, 1])\n",
    "print(\"\\nSuper Learner ROC-AUC score: %.3f\" % scoreStackXtres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save my model\n",
    "#filename = 'stacking_model.sav'\n",
    "#pickle.dump(sl, open(filename, 'wb'))\n",
    "# \n",
    "## check load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#loaded_model.predict_proba(xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results=results+[('StackingExtraTrees',scoreStackXtres)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select features to propagate\n",
    "#to_propagate=['pclass','sex_male','age'] # you can add the most important according to random forest, for example\n",
    "#pointer= [i for i,x in enumerate(df.columns) if x in to_propagate]\n",
    "#df.columns[pointer]\n",
    "#sl2 = SuperLearner(\n",
    "#    folds=5,\n",
    "#    random_state=SEED,\n",
    "#    verbose=2,\n",
    "#    backend=\"multiprocessing\",\n",
    "#    n_jobs=3\n",
    "#)\n",
    "#\n",
    "## Add the base learners and the meta learner\n",
    "#sl2.add(list(models.values()), proba=True, propagate_features=pointer)\n",
    "#sl2.add_meta(meta_learner, proba=True)\n",
    "#\n",
    "## Train the ensemble\n",
    "#sl2.fit(xtrain, ytrain)\n",
    "#\n",
    "## Predict the test set\n",
    "#p_sl2 = sl2.predict_proba(xtest)\n",
    "#scoreStackXtres2=roc_auc_score(ytest, p_sl2[:, 1])\n",
    "#print(\"\\nSuper Learner 2 ROC-AUC score: %.3f\" % scoreStackXtres2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results\n",
    "#results=results+[('StackingExtraTrees2',scoreStackXtres2)]\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporale Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tl = TemporalEnsemble()\n",
    "#tl.add(list(models.values()), proba=True)\n",
    "#tl.add_meta(meta_learner, proba=True)\n",
    "## Train the ensemble\n",
    "#tl.fit(xtrain, ytrain)\n",
    "#p_tl = tl.predict_proba(xtest)\n",
    "#scoreTempEns=roc_auc_score(ytest, p_tl[:, 1])\n",
    "#print(\"\\nTemp ROC-AUC score: %.3f\" % scoreTempEns)\n",
    "## Save results\n",
    "#results=results+[('BlendXtrees',scoreBlendXtrees)]\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bl =  BlendEnsemble(test_size=0.2, random_state=SEED,n_jobs=3)\n",
    "#\n",
    "## Add the base learners and the meta learner\n",
    "#bl.add(list(models.values()), proba=True, propagate_features=pointer)\n",
    "#bl.add_meta(meta_learner, proba=True)\n",
    "#\n",
    "## Train the ensemble\n",
    "#bl.fit(xtrain, ytrain)\n",
    "#\n",
    "## Predict the test set\n",
    "#p_bl = bl.predict_proba(xtest)\n",
    "#scoreBlendXtrees=roc_auc_score(ytest, p_bl[:, 1])\n",
    "#print(\"\\nBlend ROC-AUC score: %.3f\" % scoreBlendXtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results\n",
    "#results=results+[('BlendXtrees',scoreBlendXtrees)]\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = Subsemble(partitions=3, folds=4,partition_estimator=KMeans(3, random_state=SEED),\n",
    "#               random_state=SEED)\n",
    "#\n",
    "#sub.add(list(models.values()), proba=True, propagate_features=pointer)\n",
    "#sub.add_meta(meta_learner, proba=True)\n",
    "#\n",
    "## Train the ensemble\n",
    "#sub.fit(xtrain, ytrain)\n",
    "#\n",
    "## Predict the test set\n",
    "#p_sub = sub.predict_proba(xtest)\n",
    "#scoreSubS=roc_auc_score(ytest, p_sub[:, 1])\n",
    "#print(\"\\nSubSamble ROC-AUC score: %.3f\" % scoreSubS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results\n",
    "#results=results+[('SubSambleXtrees',scoreSubS)]\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble = SequentialEnsemble(random_state=SEED)\n",
    "#\n",
    "## The initial layer is a blended layer, same as a layer in the BlendEnsemble\n",
    "#ensemble.add('blend',\n",
    "#             list(models.values()), proba=True, propagate_features=pointer,random_state=SEED)\n",
    "#\n",
    "## The second layer is a stacked layer, same as a layer of the SuperLearner\n",
    "#ensemble.add('stack', [meta_learner, meta_learner2], proba=True,random_state=SEED)\n",
    "#\n",
    "## The third layer is a subsembled layer, same as a layer of the Subsemble\n",
    "#ensemble.add('subsemble', [meta_learner, meta_learner2], proba=True,random_state=SEED)\n",
    "#\n",
    "## The meta estimator is added as in any other ensemble\n",
    "#ensemble.add_meta(LogisticRegression(), proba=True)\n",
    "## Train the ensemble\n",
    "#ensemble.fit(xtrain, ytrain)\n",
    "#\n",
    "## Predict the test set\n",
    "#p_multi = ensemble.predict_proba(xtest)\n",
    "#scoreMultiE=roc_auc_score(ytest, p_multi[:, 1])\n",
    "#print(\"\\nMulti-Ensemble ROC-AUC score: %.3f\" % scoreMultiE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results\n",
    "#results=results+[('Multi-Layer',scoreMultiE)]\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=pd.DataFrame(results)\n",
    "results_df.columns=['Method','AUC_score']\n",
    "results_df= results_df.sort_values(by='AUC_score', ascending=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Method\", y=\"AUC_score\", data=results_df)\n",
    "ax= ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "plt.ylim(0.65,0.85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
